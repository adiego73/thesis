\chapter{Theoretical Background}
\label{chapter1}

\section{Robot Operating System}
\label{chapter1:ros}
The \ac{ROS} \nocite{ros-website} is an open source middleware that provides inter-process communication through a message passing mechanism. It is, also, a collection of libraries, tools and conventions with the aim of simplify the development of software for robots. In this sense, one of the main components of the framework are nodes which encapsulate processes and/or algorithms.

\subsection{Nodes}
\label{chapter1:ros:nodes}
Nodes are processes that perform some computation and communicate between them using a publisher/subscriber infrastructure based on topics. A node subscribes to a particular topic, and it will receive messages of that type from a publisher node. This way, publisher is hid to the subscriber, reducing the coupling between them. The advantage of this mechanism is that nodes can be developed separately once the message structure is defined, forcing developers to implement clear interfaces for communication by using a message \ac{IDL}. Moreover, this enables a modular and distributed development of the robotic system, while providing some fault tolerance and reduced code complexity.

\subsection{Topics}
\label{chapter1:ros:topics}
As mentioned before, communication between nodes is done via a publisher/subscriber architecture based on topics, which are named buses over which messages are exchanged. A node that generates data, publishes it over a topic, and this information is consumed by those nodes subscribed to that topic. There can be several publishers (as well as subscribers) for a topic. The transport protocol used for exchanging messages is defined at runtime and can be of two types: TCPROS or UDPROS. The description of these protocols is beyond the scope of this document and the reader is invited to read the ROS documentation for detailed information.

\subsection{Services}
\label{chapter1:ros:services}
As well as topics, services are a way to communicate nodes. The difference is that topics are an asynchronous way of communication, while services are synchronous. This is a key difference, because nodes decide when to trigger a service and so, services are used to retrieve specific information or to ask another node to do something out of caller's node scope.


\subsection{Tools}
\label{chapter1:ros:tools}
Regarding the tools provided by ROS, one that is be crucial for debugging and/or experimentation is the bag recording and playback. Since the message passing infrastructure is anonymous (meaning that nodes communicate between each others without knowing which node sent or received a message) it is possible to record the messages during a period of time, without taking into consideration which node sent a message and which node received it. This recorder bag is useful for debugging because it can be played back, hence reproducing a previous experiment. Also, it can be used for development of new nodes that depend on the messages contained in the bag.\\

Another useful tool provided is \ac{RViz}, a 3D visualization tool. With this tool it is possible to see the robot, orientation, reference frames, covariance matrices, etc. In addition, it is possible to draw lines, arrows, text and others, onto the environment in order to see useful information that cannot be extracted from messages.

\section{Kalman Filter}
\nocite{prob-robotics}
\ac{KF} is a technique for filtering and prediction in \emph{linear Gaussian systems} and applicable only to continuous states. It assures that the posteriors are Gaussian if the Markov assumption is hold, in addition to three conditions. The Markov assumption states that the past and future data are independent if one knows the current state; the other three conditions are the following:
\begin{enumerate}
    \item{The state transition probability $p\left( x_t | u_t, x_{t-1}\right)$ must be a linear function in its arguments. This is guaranteed by $ x_t = A_t x_{t-1} + B_t u_t + \epsilon_t $. Here, $x_t$ and $x_{t-1}$ are the state vectors, of size $n$, and $u_t$ represents the control vector, of size $m$, at time $t$; $A_t$ and $B_t$ are matrices of size $n \times n$ and $n\times m$ respectively. In this way, the state transition function becomes linear in its arguments, hence KF assumes a linear system dynamics. \\\\ $\epsilon_t$ represents the uncertainty introduced by the state transition, and it is a Gaussian random variable with zero mean and $R_t$ covariance.}
    \item{The measurement probability $p\left(z_t | x_t\right)$ must be linear in its arguments. This is guaranteed by $z_t = C_t x_t + \delta_t$, where $z_t$ represents the measurement vector of size $k$, $C_t$ is a matrix of size $k \times n$ and $\delta_t$ is a Gaussian noise with zero mean and $Q_t$ covariance.}
    \item{The initial belief should be normally distributed.}
\end{enumerate}
Given these three conditions, we are guaranteed that the posterior probability is Gaussian. \\

\begin{algorithm}[h]
    \BlankLine
    \KwIn{$\mu_{t-1}$, $\Sigma_{t-1}$, $u_t$, $z_t$}
    \BlankLine
    $\hat\mu_t = A_t \mu_{t-1} + B_t u_t$ \\
    $\hat\Sigma_t = A_t \Sigma_{t-1} A_t^T + R_t$ \\
    \BlankLine
    $K_t = \hat\Sigma_t C_t^T \left(C_t \hat\Sigma_t C_t^T + Q_t\right)^{-1}$ \\
    $\mu_t = \hat\mu_t + K_t \left(z_t - C_t \hat\mu_t \right) $ \\
    $\Sigma_t = (I - K_t C_t) \hat\Sigma_t$ \\
    \BlankLine
    \Return{$\mu_t$, $\Sigma_t$}
    \BlankLine

    \caption{Kalman Filter algorithm}
    \label{chapter1:kf:algorithm1}
\end{algorithm}

The KF algorithm's input is the belief at time $t-1$, represented by its mean ($\mu_{t-1}$) and its covariance ($\Sigma_{t-1}$), in addition to the control vector ($u_t$) and the observations ($z_t$). As a result, it returns the current belief characterized by its mean $\mu_t$ and covariance $\Sigma_t$. \\

The first step in the algorithm (lines 1 and 2), represent the prediction step. It calculates the current belief before incorporating the observations, but after adding the control vector. The estimated belief is characterized by its mean, $\hat\mu_t$ , and its covariance $\hat\Sigma_t$.\\

The second step (from line 3 to 5) starts by calculating $K_t$, the Kalman gain, which specifies the degree in which the observation is incorporated to the new state estimate. Following, at line 4, the new mean is estimated by means of the Kalman gain and the \emph{innovation}, which is the difference between the observation $z_t$ and the expected measurement $C_t \hat\mu_t$. Finally, the new covariance is calculated. \\

\subsection{Extended Kalman Filter}

\section{Simultaneous Localization and Mapping}

\subsection{EKF-SLAM}